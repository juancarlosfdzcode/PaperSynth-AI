{
  "status": "success",
  "papers_count": 15,
  "papers": [
    {
      "id": 1,
      "arxiv_id": "2602.12281v1",
      "fetched_date": "2026-02-15T16:13:13.883980",
      "published": "2026-02-12T18:59:59+00:00",
      "title": "Scaling Verification Can Be More Effective than Scaling Policy Learning for Vision-Language-Action Alignment",
      "authors": [
        "Jacky Kwok",
        "Xilun Zhang",
        "Mengdi Xu",
        "Yuejiang Liu",
        "Azalia Mirhoseini",
        "Chelsea Finn",
        "Marco Pavone"
      ],
      "summary": "The long-standing vision of general-purpose robots hinges on their ability to understand and act upon natural language instructions. Vision-Language-Action (VLA) models have made remarkable progress toward this goal, yet their generated actions can still misalign with the given instructions. In this paper, we investigate test-time verification as a means to shrink the intention-action gap. We first characterize the test-time scaling law for embodied instruction following and demonstrate that jointly scaling the number of rephrased instructions and generated actions greatly increases test-time sample diversity, often recovering correct actions more efficiently than scaling each dimension independently. To capitalize on these scaling laws, we present CoVer, a contrastive verifier for vision-language-action alignment, and show that our architecture scales gracefully with additional computational resources and data. We then introduce boot-time compute and a hierarchical verification inference pipeline for VLAs. At deployment, our framework precomputes a diverse set of rephrased instructions from a Vision-Language-Model (VLM), repeatedly generates action candidates for each instruction, and then uses a verifier to select the optimal high-level prompt and low-level action chunks. Compared to scaling policy pre-training on the same data, our verification approach yields 22 gains in-distribution and 13 out-of-distribution on the SIMPLER benchmark, with a further 45 improvement in real-world experiments. On the PolaRiS benchmark, CoVer achieves 14 gains in task progress and 9 in success rate.",
      "primary_category": "cs.RO",
      "categories": [
        "cs.RO",
        "cs.AI",
        "eess.SY"
      ],
      "pdf_url": "https://arxiv.org/pdf/2602.12281v1",
      "ar5iv_url": "https://ar5iv.labs.arxiv.org/html/2602.12281v1",
      "arxiv_url": "https://arxiv.org/abs/2602.12281v1"
    },
    {
      "id": 2,
      "arxiv_id": "2602.12279v1",
      "fetched_date": "2026-02-15T16:13:13.884159",
      "published": "2026-02-12T18:59:49+00:00",
      "title": "UniT: Unified Multimodal Chain-of-Thought Test-time Scaling",
      "authors": [
        "Leon Liangyu Chen",
        "Haoyu Ma",
        "Zhipeng Fan",
        "Ziqi Huang",
        "Animesh Sinha",
        "Xiaoliang Dai",
        "Jialiang Wang",
        "Zecheng He",
        "Jianwei Yang",
        "Chunyuan Li",
        "Junzhe Sun",
        "Chu Wang",
        "Serena Yeung-Levy",
        "Felix Juefei-Xu"
      ],
      "summary": "Unified models can handle both multimodal understanding and generation within a single architecture, yet they typically operate in a single pass without iteratively refining their outputs. Many multimodal tasks, especially those involving complex spatial compositions, multiple interacting objects, or evolving instructions, require decomposing instructions, verifying intermediate results, and making iterative corrections. While test-time scaling (TTS) has demonstrated that allocating additional inference compute for iterative reasoning substantially improves language model performance, extending this paradigm to unified multimodal models remains an open challenge. We introduce UniT, a framework for multimodal chain-of-thought test-time scaling that enables a single unified model to reason, verify, and refine across multiple rounds. UniT combines agentic data synthesis, unified model training, and flexible test-time inference to elicit cognitive behaviors including verification, subgoal decomposition, and content memory. Our key findings are: (1) unified models trained on short reasoning trajectories generalize to longer inference chains at test time; (2) sequential chain-of-thought reasoning provides a more scalable and compute-efficient TTS strategy than parallel sampling; (3) training on generation and editing trajectories improves out-of-distribution visual reasoning. These results establish multimodal test-time scaling as an effective paradigm for advancing both generation and understanding in unified models.",
      "primary_category": "cs.CV",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "pdf_url": "https://arxiv.org/pdf/2602.12279v1",
      "ar5iv_url": "https://ar5iv.labs.arxiv.org/html/2602.12279v1",
      "arxiv_url": "https://arxiv.org/abs/2602.12279v1"
    },
    {
      "id": 3,
      "arxiv_id": "2602.12278v1",
      "fetched_date": "2026-02-15T16:13:13.884232",
      "published": "2026-02-12T18:59:35+00:00",
      "title": "AttentionRetriever: Attention Layers are Secretly Long Document Retrievers",
      "authors": [
        "David Jiahao Fu",
        "Lam Thanh Do",
        "Jiayu Li",
        "Kevin Chen-Chuan Chang"
      ],
      "summary": "Retrieval augmented generation (RAG) has been widely adopted to help Large Language Models (LLMs) to process tasks involving long documents. However, existing retrieval models are not designed for long document retrieval and fail to address several key challenges of long document retrieval, including context-awareness, causal dependence, and scope of retrieval. In this paper, we proposed AttentionRetriever, a novel long document retrieval model that leverages attention mechanism and entity-based retrieval to build context-aware embeddings for long document and determine the scope of retrieval. With extensive experiments, we found AttentionRetriever is able to outperform existing retrieval models on long document retrieval datasets by a large margin while remaining as efficient as dense retrieval models.",
      "primary_category": "cs.IR",
      "categories": [
        "cs.IR",
        "cs.AI"
      ],
      "pdf_url": "https://arxiv.org/pdf/2602.12278v1",
      "ar5iv_url": "https://ar5iv.labs.arxiv.org/html/2602.12278v1",
      "arxiv_url": "https://arxiv.org/abs/2602.12278v1"
    },
    {
      "id": 4,
      "arxiv_id": "2602.12276v1",
      "fetched_date": "2026-02-15T16:13:13.884285",
      "published": "2026-02-12T18:58:30+00:00",
      "title": "Agentic Test-Time Scaling for WebAgents",
      "authors": [
        "Nicholas Lee",
        "Lutfi Eren Erdogan",
        "Chris Joseph John",
        "Surya Krishnapillai",
        "Michael W. Mahoney",
        "Kurt Keutzer",
        "Amir Gholami"
      ],
      "summary": "Test-time scaling has become a standard way to improve performance and boost reliability of neural network models. However, its behavior on agentic, multi-step tasks remains less well-understood: small per-step errors can compound over long horizons; and we find that naive policies that uniformly increase sampling show diminishing returns. In this work, we present CATTS, a simple technique for dynamically allocating compute for multi-step agents. We first conduct an empirical study of inference-time scaling for web agents. We find that uniformly increasing per-step compute quickly saturates in long-horizon environments. We then investigate stronger aggregation strategies, including an LLM-based Arbiter that can outperform naive voting, but that can overrule high-consensus decisions. We show that uncertainty statistics derived from the agents own vote distribution (entropy and top-1top-2 margin) correlate with downstream success and provide a practical signal for dynamic compute allocation. Based on these findings, we introduce Confidence-Aware Test-Time Scaling (CATTS), which uses vote-derived uncertainty to allocate compute only when decisions are genuinely contentious. CATTS improves performance on WebArena-Lite and GoBrowse by up to 9.1 over React while using up to 2.3x fewer tokens than uniform scaling, providing both efficiency gains and an interpretable decision rule.",
      "primary_category": "cs.AI",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "pdf_url": "https://arxiv.org/pdf/2602.12276v1",
      "ar5iv_url": "https://ar5iv.labs.arxiv.org/html/2602.12276v1",
      "arxiv_url": "https://arxiv.org/abs/2602.12276v1"
    },
    {
      "id": 5,
      "arxiv_id": "2602.12275v1",
      "fetched_date": "2026-02-15T16:13:13.884353",
      "published": "2026-02-12T18:58:28+00:00",
      "title": "On-Policy Context Distillation for Language Models",
      "authors": [
        "Tianzhu Ye",
        "Li Dong",
        "Xun Wu",
        "Shaohan Huang",
        "Furu Wei"
      ],
      "summary": "Context distillation enables language models to internalize in-context knowledge into their parameters. In our work, we propose On-Policy Context Distillation (OPCD), a framework that bridges on-policy distillation with context distillation by training a student model on its own generated trajectories while minimizing reverse Kullback-Leibler divergence against a context-conditioned teacher. We demonstrate the effectiveness of OPCD on two important applications: experiential knowledge distillation, where models extract and consolidate transferable knowledge from their historical solution traces, and system prompt distillation, where models internalize beneficial behaviors encoded in optimized prompts. Across mathematical reasoning, text-based games, and domain-specific tasks, OPCD consistently outperforms baseline methods, achieving higher task accuracy while better preserving out-of-distribution capabilities. We further show that OPCD enables effective cross-size distillation, where smaller student models can internalize experiential knowledge from larger teachers.",
      "primary_category": "cs.CL",
      "categories": [
        "cs.CL"
      ],
      "pdf_url": "https://arxiv.org/pdf/2602.12275v1",
      "ar5iv_url": "https://ar5iv.labs.arxiv.org/html/2602.12275v1",
      "arxiv_url": "https://arxiv.org/abs/2602.12275v1"
    },
    {
      "id": 6,
      "arxiv_id": "2602.12274v1",
      "fetched_date": "2026-02-15T16:13:13.884410",
      "published": "2026-02-12T18:58:12+00:00",
      "title": "Function-Space Decoupled Diffusion for Forward and Inverse Modeling in Carbon Capture and Storage",
      "authors": [
        "Xin Ju",
        "Jiachen Yao",
        "Anima Anandkumar",
        "Sally M. Benson",
        "Gege Wen"
      ],
      "summary": "Accurate characterization of subsurface flow is critical for Carbon Capture and Storage (CCS) but remains challenged by the ill-posed nature of inverse problems with sparse observations. We present Fun-DDPS, a generative framework that combines function-space diffusion models with differentiable neural operator surrogates for both forward and inverse modeling. Our approach learns a prior distribution over geological parameters (geomodel) using a single-channel diffusion model, then leverages a Local Neural Operator (LNO) surrogate to provide physics-consistent guidance for cross-field conditioning on the dynamics field. This decoupling allows the diffusion prior to robustly recover missing information in parameter space, while the surrogate provides efficient gradient-based guidance for data assimilation. We demonstrate Fun-DDPS on synthetic CCS modeling datasets, achieving two key results: (1) For forward modeling with only 25 observations, Fun-DDPS achieves 7.7 relative error compared to 86.9 for standard surrogates (an 11x improvement), proving its capability to handle extreme data sparsity where deterministic methods fail. (2) We provide the first rigorous validation of diffusion-based inverse solvers against asymptotically exact Rejection Sampling (RS) posteriors. Both Fun-DDPS and the joint-state baseline (Fun-DPS) achieve Jensen-Shannon divergence less than 0.06 against the ground truth. Crucially, Fun-DDPS produces physically consistent realizations free from the high-frequency artifacts observed in joint-state baselines, achieving this with 4x improved sample efficiency compared to rejection sampling.",
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "physics.geo-ph"
      ],
      "pdf_url": "https://arxiv.org/pdf/2602.12274v1",
      "ar5iv_url": "https://ar5iv.labs.arxiv.org/html/2602.12274v1",
      "arxiv_url": "https://arxiv.org/abs/2602.12274v1"
    },
    {
      "id": 7,
      "arxiv_id": "2602.12273v1",
      "fetched_date": "2026-02-15T16:13:13.884487",
      "published": "2026-02-12T18:57:43+00:00",
      "title": "Learning to Control: The iUzawa-Net for Nonsmooth Optimal Control of Linear PDEs",
      "authors": [
        "Yongcun Song",
        "Xiaoming Yuan",
        "Hangrui Yue",
        "Tianyou Zeng"
      ],
      "summary": "We propose an optimization-informed deep neural network approach, named iUzawa-Net, aiming for the first solver that enables real-time solutions for a class of nonsmooth optimal control problems of linear partial differential equations (PDEs). The iUzawa-Net unrolls an inexact Uzawa method for saddle point problems, replacing classical preconditioners and PDE solvers with specifically designed learnable neural networks. We prove universal approximation properties and establish the asymptotic varepsilon-optimality for the iUzawa-Net, and validate its promising numerical efficiency through nonsmooth elliptic and parabolic optimal control problems. Our techniques offer a versatile framework for designing and analyzing various optimization-informed deep learning approaches to optimal control and other PDE-constrained optimization problems. The proposed learning-to-control approach synergizes model-based optimization algorithms and data-driven deep learning techniques, inheriting the merits of both methodologies.",
      "primary_category": "math.OC",
      "categories": [
        "math.OC",
        "cs.LG",
        "math.NA"
      ],
      "pdf_url": "https://arxiv.org/pdf/2602.12273v1",
      "ar5iv_url": "https://ar5iv.labs.arxiv.org/html/2602.12273v1",
      "arxiv_url": "https://arxiv.org/abs/2602.12273v1"
    },
    {
      "id": 8,
      "arxiv_id": "2602.12271v1",
      "fetched_date": "2026-02-15T16:13:13.884547",
      "published": "2026-02-12T18:56:53+00:00",
      "title": "MonarchRT: Efficient Attention for Real-Time Video Generation",
      "authors": [
        "Krish Agarwal",
        "Zhuoming Chen",
        "Cheng Luo",
        "Yongqi Chen",
        "Haizhong Zheng",
        "Xun Huang",
        "Atri Rudra",
        "Beidi Chen"
      ],
      "summary": "Real-time video generation with Diffusion Transformers is bottlenecked by the quadratic cost of 3D self-attention, especially in real-time regimes that are both few-step and autoregressive, where errors compound across time and each denoising step must carry substantially more information. In this setting, we find that prior sparse-attention approximations break down, despite showing strong results for bidirectional, many-step diffusion. Specifically, we observe that video attention is not reliably sparse, but instead combines pronounced periodic structure driven by spatiotemporal position with dynamic, sparse semantic correspondences and dense mixing, exceeding the representational capacity of even oracle top-k attention. Building on this insight, we propose Monarch-RT, a structured attention parameterization for video diffusion models that factorizes attention using Monarch matrices. Through appropriately aligned block structure and our extended tiled Monarch parameterization, we achieve high expressivity while preserving computational efficiency. We further overcome the overhead of parameterization through finetuning, with custom Triton kernels. We first validate the high efficacy of Monarch-RT over existing sparse baselines designed only for bidirectional models. We further observe that Monarch-RT attains up to 95 attention sparsity with no loss in quality when applied to the state-of-the-art model Self-Forcing, making Monarch-RT a pioneering work on highly-capable sparse attention parameterization for real-time video generation. Our optimized implementation outperforms FlashAttention-2, FlashAttention-3, and FlashAttention-4 kernels on Nvidia RTX 5090, H100, and B200 GPUs respectively, providing kernel speedups in the range of 1.4-11.8X. This enables us, for the first time, to achieve true real-time video generation with Self-Forcing at 16 FPS on a single RTX 5090.",
      "primary_category": "cs.CV",
      "categories": [
        "cs.CV",
        "cs.LG"
      ],
      "pdf_url": "https://arxiv.org/pdf/2602.12271v1",
      "ar5iv_url": "https://ar5iv.labs.arxiv.org/html/2602.12271v1",
      "arxiv_url": "https://arxiv.org/abs/2602.12271v1"
    },
    {
      "id": 9,
      "arxiv_id": "2602.12270v1",
      "fetched_date": "2026-02-15T16:13:13.884624",
      "published": "2026-02-12T18:56:42+00:00",
      "title": "Creative Ownership in the Age of AI",
      "authors": [
        "Annie Liang",
        "Jay Lu"
      ],
      "summary": "Copyright law focuses on whether a new work is substantially similar to an existing one, but generative AI can closely imitate style without copying content, a capability now central to ongoing litigation. We argue that existing definitions of infringement are ill-suited to this setting and propose a new criterion: a generative AI output infringes on an existing work if it could not have been generated without that work in its training corpus. To operationalize this definition, we model generative systems as closure operators mapping a corpus of existing works to an output of new works. AI generated outputs are emphpermissible if they do not infringe on any existing work according to our criterion. Our results characterize structural properties of permissible generation and reveal a sharp asymptotic dichotomy: when the process of organic creations is light-tailed, dependence on individual works eventually vanishes, so that regulation imposes no limits on AI generation; with heavy-tailed creations, regulation can be persistently constraining.",
      "primary_category": "econ.TH",
      "categories": [
        "econ.TH",
        "cs.AI",
        "cs.GT"
      ],
      "pdf_url": "https://arxiv.org/pdf/2602.12270v1",
      "ar5iv_url": "https://ar5iv.labs.arxiv.org/html/2602.12270v1",
      "arxiv_url": "https://arxiv.org/abs/2602.12270v1"
    },
    {
      "id": 10,
      "arxiv_id": "2602.12268v1",
      "fetched_date": "2026-02-15T16:13:13.884688",
      "published": "2026-02-12T18:55:09+00:00",
      "title": "CM2: Reinforcement Learning with Checklist Rewards for Multi-Turn and Multi-Step Agentic Tool Use",
      "authors": [
        "Zhen Zhang",
        "Kaiqiang Song",
        "Xun Wang",
        "Yebowen Hu",
        "Weixiang Yan",
        "Chenyang Zhao",
        "Henry Peng Zou",
        "Haoyun Deng",
        "Sathish Reddy Indurthi",
        "Shujian Liu",
        "Simin Ma",
        "Xiaoyang Wang",
        "Xin Eric Wang",
        "Song Wang"
      ],
      "summary": "AI agents are increasingly used to solve real-world tasks by reasoning over multi-turn user interactions and invoking external tools. However, applying reinforcement learning to such settings remains difficult: realistic objectives often lack verifiable rewards and instead emphasize open-ended behaviors; moreover, RL for multi-turn, multi-step agentic tool use is still underexplored; and building and maintaining executable tool environments is costly, limiting scale and coverage. We propose CM2, an RL framework that replaces verifiable outcome rewards with checklist rewards. CM2 decomposes each turns intended behavior into fine-grained binary criteria with explicit evidence grounding and structured metadata, turning open-ended judging into more stable classification-style decisions. To balance stability and informativeness, our method adopts a strategy of sparse reward assignment but dense evaluation criteria. Training is performed in a scalable LLM-simulated tool environment, avoiding heavy engineering for large tool sets. Experiments show that CM2 consistently improves over supervised fine-tuning. Starting from an 8B Base model and training on an 8k-example RL dataset, CM2 improves over the SFT counterpart by 8 points on tau-Bench, by 10 points on BFCL-V4, and by 12 points on ToolSandbox. The results match or even outperform similarly sized open-source baselines, including the judging model. CM2 thus provides a scalable recipe for optimizing multi-turn, multi-step tool-using agents without relying on verifiable rewards. Code provided by the open-source community: https:github.comnamezhenzhangCM2-RLCR-Tool-Agent.",
      "primary_category": "cs.AI",
      "categories": [
        "cs.AI"
      ],
      "pdf_url": "https://arxiv.org/pdf/2602.12268v1",
      "ar5iv_url": "https://ar5iv.labs.arxiv.org/html/2602.12268v1",
      "arxiv_url": "https://arxiv.org/abs/2602.12268v1"
    },
    {
      "id": 11,
      "arxiv_id": "2602.12267v1",
      "fetched_date": "2026-02-15T16:13:13.884761",
      "published": "2026-02-12T18:54:57+00:00",
      "title": "Self-Supervised Learning via Flow-Guided Neural Operator on Time-Series Data",
      "authors": [
        "Duy Nguyen",
        "Jiachen Yao",
        "Jiayun Wang",
        "Julius Berner",
        "Animashree Anandkumar"
      ],
      "summary": "Self-supervised learning (SSL) is a powerful paradigm for learning from unlabeled time-series data. However, popular methods such as masked autoencoders (MAEs) rely on reconstructing inputs from a fixed, predetermined masking ratio. Instead of this static design, we propose treating the corruption level as a new degree of freedom for representation learning, enhancing flexibility and performance. To achieve this, we introduce the Flow-Guided Neural Operator (FGNO), a novel framework combining operator learning with flow matching for SSL training. FGNO learns mappings in functional spaces by using Short-Time Fourier Transform to unify different time resolutions. We extract a rich hierarchy of features by tapping into different network layers and flow times that apply varying strengths of noise to the input data. This enables the extraction of versatile representations, from low-level patterns to high-level global features, using a single model adaptable to specific tasks. Unlike prior generative SSL methods that use noisy inputs during inference, we propose using clean inputs for representation extraction while learning representations with noise; this eliminates randomness and boosts accuracy. We evaluate FGNO across three biomedical domains, where it consistently outperforms established baselines. Our method yields up to 35 AUROC gains in neural signal decoding (BrainTreeBank), 16 RMSE reductions in skin temperature prediction (DREAMT), and over 20 improvement in accuracy and macro-F1 on SleepEDF under low-data regimes. These results highlight FGNOs robustness to data scarcity and its superior capacity to learn expressive representations for diverse time series.",
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG"
      ],
      "pdf_url": "https://arxiv.org/pdf/2602.12267v1",
      "ar5iv_url": "https://ar5iv.labs.arxiv.org/html/2602.12267v1",
      "arxiv_url": "https://arxiv.org/abs/2602.12267v1"
    },
    {
      "id": 12,
      "arxiv_id": "2602.12262v1",
      "fetched_date": "2026-02-15T16:13:13.884841",
      "published": "2026-02-12T18:52:35+00:00",
      "title": "T3D: Few-Step Diffusion Language Models via Trajectory Self-Distillation with Direct Discriminative Optimization",
      "authors": [
        "Tunyu Zhang",
        "Xinxi Zhang",
        "Ligong Han",
        "Haizhou Shi",
        "Xiaoxiao He",
        "Zhuowei Li",
        "Hao Wang",
        "Kai Xu",
        "Akash Srivastava",
        "Hao Wang",
        "Vladimir Pavlovic",
        "Dimitris N. Metaxas"
      ],
      "summary": "Diffusion large language models (DLLMs) have the potential to enable fast text generation by decoding multiple tokens in parallel. However, in practice, their inference efficiency is constrained by the need for many refinement steps, while aggressively reducing the number of steps leads to a substantial degradation in generation quality. To alleviate this, we propose a trajectory self-distillation framework that improves few-step decoding by distilling the models own generative trajectories. We incorporate Direct Discriminative Optimization (DDO), a reverse-KL objective that promotes mode-seeking distillation and encourages the student to concentrate on high-probability teacher modes. Across benchmarks, our approach consistently outperforms strong few-step baselines and standard training under tight step budgets. Although full-step decoding remains superior, we substantially narrow the gap, establishing a strong foundation towards practical few-step DLLMs. The source code is available at https:github.comTyrion58T3D.",
      "primary_category": "cs.CL",
      "categories": [
        "cs.CL",
        "cs.LG"
      ],
      "pdf_url": "https://arxiv.org/pdf/2602.12262v1",
      "ar5iv_url": "https://ar5iv.labs.arxiv.org/html/2602.12262v1",
      "arxiv_url": "https://arxiv.org/abs/2602.12262v1"
    },
    {
      "id": 13,
      "arxiv_id": "2602.12259v1",
      "fetched_date": "2026-02-15T16:13:13.884896",
      "published": "2026-02-12T18:49:27+00:00",
      "title": "Think like a Scientist: Physics-guided LLM Agent for Equation Discovery",
      "authors": [
        "Jianke Yang",
        "Ohm Venkatachalam",
        "Mohammad Kianezhad",
        "Sharvaree Vadgama",
        "Rose Yu"
      ],
      "summary": "Explaining observed phenomena through symbolic, interpretable formulas is a fundamental goal of science. Recently, large language models (LLMs) have emerged as promising tools for symbolic equation discovery, owing to their broad domain knowledge and strong reasoning capabilities. However, most existing LLM-based systems try to guess equations directly from data, without modeling the multi-step reasoning process that scientists often follow: first inferring physical properties such as symmetries, then using these as priors to restrict the space of candidate equations. We introduce KeplerAgent, an agentic framework that explicitly follows this scientific reasoning process. The agent coordinates physics-based tools to extract intermediate structure and uses these results to configure symbolic regression engines such as PySINDy and PySR, including their function libraries and structural constraints. Across a suite of physical equation benchmarks, KeplerAgent achieves substantially higher symbolic accuracy and greater robustness to noisy data than both LLM and traditional baselines.",
      "primary_category": "cs.AI",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "pdf_url": "https://arxiv.org/pdf/2602.12259v1",
      "ar5iv_url": "https://ar5iv.labs.arxiv.org/html/2602.12259v1",
      "arxiv_url": "https://arxiv.org/abs/2602.12259v1"
    },
    {
      "id": 14,
      "arxiv_id": "2602.12257v1",
      "fetched_date": "2026-02-15T16:13:13.884950",
      "published": "2026-02-12T18:45:42+00:00",
      "title": "On the implicit regularization of Langevin dynamics with projected noise",
      "authors": [
        "Govind Menon",
        "Austin J. Stromme",
        "Adrien Vacher"
      ],
      "summary": "We study Langevin dynamics with noise projected onto the directions orthogonal to an isometric group action. This mathematical model is introduced to shed new light on the effects of symmetry on stochastic gradient descent for over-parametrized models. Our main result identifies a novel form of implicit regularization: when the initial and target density are both invariant under the group action, Langevin dynamics with projected noise is equivalent in law to Langevin dynamics with isotropic diffusion but with an additional drift term proportional to the negative log volume of the group orbit. We prove this result by constructing a coupling of the two processes via a third process on the group itself, and identify the additional drift as the mean curvature of the orbits.",
      "primary_category": "math.PR",
      "categories": [
        "math.PR",
        "cs.AI"
      ],
      "pdf_url": "https://arxiv.org/pdf/2602.12257v1",
      "ar5iv_url": "https://ar5iv.labs.arxiv.org/html/2602.12257v1",
      "arxiv_url": "https://arxiv.org/abs/2602.12257v1"
    },
    {
      "id": 15,
      "arxiv_id": "2602.12251v1",
      "fetched_date": "2026-02-15T16:13:13.884997",
      "published": "2026-02-12T18:37:23+00:00",
      "title": "A technical curriculum on language-oriented artificial intelligence in translation and specialised communication",
      "authors": [
        "Ralph Kr√ºger"
      ],
      "summary": "This paper presents a technical curriculum on language-oriented artificial intelligence (AI) in the language and translation (LT) industry. The curriculum aims to foster domain-specific technical AI literacy among stakeholders in the fields of translation and specialised communication by exposing them to the conceptual and technicalalgorithmic foundations of modern language-oriented AI in an accessible way. The core curriculum focuses on 1) vector embeddings, 2) the technical foundations of neural networks, 3) tokenization and 4) transformer neural networks. It is intended to help users develop computational thinking as well as algorithmic awareness and algorithmic agency, ultimately contributing to their digital resilience in AI-driven work environments. The didactic suitability of the curriculum was tested in an AI-focused MA course at the Institute of Translation and Multilingual Communication at TH Koeln. Results suggest the didactic effectiveness of the curriculum, but participant feedback indicates that it should be embedded into higher-level didactic scaffolding - e.g., in the form of lecturer support - in order to enable optimal learning conditions.",
      "primary_category": "cs.CL",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.HC"
      ],
      "pdf_url": "https://arxiv.org/pdf/2602.12251v1",
      "ar5iv_url": "https://ar5iv.labs.arxiv.org/html/2602.12251v1",
      "arxiv_url": "https://arxiv.org/abs/2602.12251v1"
    }
  ],
  "query_used": "(cat:cs.AI OR cat:cs.LG OR cat:cs.CL) AND (large language models OR transformers OR attention mechanism)",
  "categories_searched": [
    "cs.AI",
    "cs.LG",
    "cs.CL"
  ]
}